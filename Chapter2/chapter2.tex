%!TEX root = ../thesis.tex
%*******************************************************************************
%****************************** Second Chapter *********************************
%*******************************************************************************

\chapter{Adjoint based shape optimization}

\ifpdf
    \graphicspath{{Chapter2/Figs/Raster/}{Chapter2/Figs/PDF/}{Chapter2/Figs/}}
\else
    \graphicspath{{Chapter2/Figs/Vector/}{Chapter2/Figs/}}
\fi

Here an later we use the following denominations for scalar products:

\begin{subequations}
\begin{align}
          \left< \cdot, \cdot \right> = \int_{\Omega} dx (\cdot, \cdot ), \\
          \left\{ \cdot, \cdot \right\} = \int_{T} dt (\cdot, \cdot ), \\
          \left[ \cdot, \cdot  \right] = \int_{\Omega} dx\int_{T} dt (\cdot, \cdot )
\end{align}
\end{subequations}


\section{Pedagogical one dimensional optimization}

To start with, we consider two one-dimensional optimization problems: parameter-based unsteady Burgers equation, and Helmholtz equation with adjustable shape. These examples are aimed to give an insight into construction of adjoint systems and how to obtain cost function gradient with respect to different changes in the initial problem.

\subsection{Burgers equation: sensitivity to control parameters}

Burgers equation (\ref{eq:BurgEq}), is a nonlinear partial differential equation describing one-dimensional viscous fluid. We consider it to be defined in closed spatial domain $x \in [A,B]$ and for time interval $t \in [0, T]$.

\begin{equation}
\label{eq:BurgEq}
    u_t + u u_x - \nu u_{xx} = 0
\end{equation}

Initial condition $u(x,0)$ is given, as well as two Dirichlet boundary conditions:

\begin{subequations}
\label{eq:BurgEqBCs}
\begin{align}
    u(x,0) = u_0(x), \\
    u(A,t) = f(t), \\
    u(B,t) = 1.
\end{align}
\end{subequations}

Here the left boundary condition, $f(t)$, will act as a control parameter. We would like to optimize it in order to minimize a cost function, for instance, time-averaged viscous dissipation:

\begin{equation}
\mathcal{J} = \left[ \nu \left( \frac{\partial u}{\partial x} \right)^2 \right]
\end{equation}

Following \cite{CossuIntr}, in this example we will treat initial and boundary conditions (\ref{eq:BurgEqBCs}) as given constraints, i.e. in the same as the Burgers equation itself. Another approach, which leads to the same result, is to apply given boundary conditions after the augmented cost function is formed.

The first step is to form a so-called Lagrangian of the system, by adding all state equations multiplied by Lagrange variables to the cost function. This gives:

\begin{subequations}
\begin{align}
    \label{eq:BurgEqAdj0}
    \mathcal{L} = \mathcal{J} - \left[ \lambda, u_t + u u_x - \nu u_{xx} \right] -\\
    - \left< b, u(x,0) - u_0 \right> -  \left\{ C_{\alpha}, u(A,t) - f(t) \right\}  -  \left\{ C_{\beta}, u(B,t) - 1 \right\}
\end{align}
\end{subequations}

Here $\lambda$ is an Lagrange state multiplier, $b$ and $C_{\alpha}, C_{\beta}$ are Lagrange multipliers for initial and boundary conditions, respectively. One can see, that partial derivatives of $\mathcal{L}$ with respect to $\lambda$ produce initial state equation, and initial and boundary equations while differentiation with respect to $b, C_{\alpha}, C_{\beta}$. To construct the adjoint operator, we integrate the differential form in (\ref{eq:BurgEqAdj0}) by parts and apply divergence theorem, which results in:

\begin{subequations}
\label{eq:BurgEqAdj}
\begin{align}
    \label{eq:BurgEqAdj1}
    \mathcal{L} = \mathcal{J} - \left[ -\lambda_t - \frac{1}{2} u \lambda_x - \nu \lambda_{xx}, u \right] -\\
    - \left< \lambda, u \right>^T_0 - \left\{\frac{1}{2} \lambda u - \nu \lambda_x, u \right\}^B_A + \left\{ \nu \lambda, u_x \right\}^B_A - \\
    - \left< b, u(x,0) - u_0 \right> -  \left\{ C_{\alpha}, u(A,t) - f(t) \right\}  -  \left\{ C_{\beta}, u(B,t) - 1 \right\}
\end{align}
\end{subequations}

Now, the total variation of the Lagrangian $\delta \mathcal{L}$ can be written as:

\begin{subequations}
\begin{align}
    \label{eq:BurgEqAdjVariation}
    0 = \delta \mathcal{L} = \delta \mathcal{J} + \left[ \lambda_t + u \lambda_x + \nu \lambda_{xx}, \delta u \right] -\\
    - \left< \lambda(x,T), \delta u(x,T) \right> + \left< \lambda(x,0), \delta u(x,0) \right> - \\
    - \left\{ \lambda u - \nu \lambda_x, \delta u \right\}^B_A + \left\{ \nu \lambda, (\delta u)_x \right\}^B_A - \\
    - \left< b, \delta u(x,0) \right> -  \left\{ C_{\alpha}, \delta u(A,t) \right\}  -  \left\{ C_{\beta}, \delta u(B,t) \right\}
\end{align}
\end{subequations}

Unspecified variation of the cost function, $\delta \mathcal{J}$, is:

\begin{equation}
\delta \mathcal{J} = \left[ - 2 \nu u_xx, \delta u \right] + \left\{ 2 \nu u_x, \delta u  \right\}^B_A
\end{equation}

Finally, gathering terms with the same variation quantity, extracts the adjoint set of equations. The $\left[ \cdot , \delta u \right] $ terms give the adjoint state equation:

\begin{equation}
\lambda_t + u \lambda_x + \nu \lambda_{xx} = 2 \nu u_{xx}
\end{equation}

Worth mentioning that despite this equation is quite similar to the original Burgers equation - it has temporal derivative, convective, and a viscous term, it is linear on $\lambda$, and has a source function. Moreover, viscosity has a different sign in comparison to the direct problem, thus the adjoint problem will be well-posed only if propagates back in time, starting with 'initial data' at the final time $t = T$ \cite{Giles2000}. This means, that integration in time should follow the direct solution backwards.

Gathering the rest terms provides the necessary adjoint boundary and initial conditions:

\begin{subequations}
\begin{align}
    \label{eq:BurgEqAdjBCt0}
    & \delta u(x,0): \ \ \lambda - b = 0 & \Rightarrow \ \ & b = \lambda(x,0),\\
    \label{eq:BurgEqAdjBCtT}
    & \delta u(x,T): \ \ \lambda = 0 & \Rightarrow \ \ & \lambda(x,T) = 0 ,\\
    & \delta u_x(A,t): \ \ \nu \lambda = 0 & \Rightarrow \ \ & \lambda(A,t) = 0, \\
    & \delta u_x(B,t): \ \ \nu \lambda = 0 & \Rightarrow \ \ & \lambda(B,t) = 0, \\
    & \delta u(A,t): \ \ 2 \nu u_x - \lambda u - \nu \lambda_x + C_{\alpha} = 0, \\
    & \delta u(B,t): \ \ 2 \nu u_x - \lambda u - \nu \lambda_x - C_{\beta} = 0
\end{align}
\end{subequations}

The first two conditions (\ref{eq:BurgEqAdjBCt0}) and (\ref{eq:BurgEqAdjBCtT}) are sensitivity to the initial condition $u(x,0) = u_0$ and the adjoint initial condition, which says that $\lambda(x,T) = 0$; the following two are adjoint boundary conditions, and the two last give us the values of $C_{\alpha}, C_{\beta}$ at $x = A$ and $x = B$, respectively.

Finally, from (\ref{eq:BurgEqAdj}) it is clear, that the sensitivity with respect to the boundary condition $u(A,t) = f(t)$ equals to:

\begin{equation}
\frac{\partial \mathcal{L}}{\partial f} \delta f = \left\{C_{\alpha} , \delta f(t)  \right\}
\end{equation}

And consequently, the gradient of the cost function with respect to $f(t)$ becomes:

\begin{equation}
\nabla \mathcal{J}[f] = C_{\alpha} = -2 \nu u_x (A,t) + \nu \lambda_x (A,t)
\end{equation}

\subsection{Shape optimization of linear acoustic problem}

\clearpage

\section{Adjoints for incompressible Navier-Stokes equation}
\subsection{Governing equations}
\subsection{Adjoint boundary conditions}
\subsection{Shape derivatives and Hadamard structure}
\subsection{Time dependent flow optimization}

\section{Adjoints for acoustic problem}
\subsection{Governing equations}
\subsection{Adjoint boundary conditions}
\subsection{Shape derivatives and Hadamard structure}

\section{Taylor testing for adjoint gradient}
