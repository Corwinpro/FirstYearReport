%!TEX root = ../thesis.tex
%*******************************************************************************
%****************************** Second Chapter *********************************
%*******************************************************************************

\chapter{Adjoint based shape optimization}

\ifpdf
    \graphicspath{{Chapter2/Figs/Raster/}{Chapter2/Figs/PDF/}{Chapter2/Figs/}}
\else
    \graphicspath{{Chapter2/Figs/Vector/}{Chapter2/Figs/}}
\fi

Here an later we use the following denominations for scalar products:

\begin{subequations}
\begin{align}
          \left< \cdot, \cdot \right> = \int_{\Omega} dx (\cdot, \cdot ), \\
          \left\{ \cdot, \cdot \right\} = \int_{T} dt (\cdot, \cdot ), \\
          \left[ \cdot, \cdot  \right] = \int_{\Omega} dx\int_{T} dt (\cdot, \cdot )
\end{align}
\end{subequations}


\section{Pedagogical one dimensional optimization}

To start with, we consider two one-dimensional optimization problems: parameter-based unsteady Burgers equation, and Helmholtz equation with adjustable shape. These examples are aimed to give an insight into construction of adjoint systems and how to obtain cost function gradient with respect to different changes in the initial problem.

\subsection{Burgers equation: sensitivity to control parameters}

Burgers equation (\ref{eq:BurgEq}), is a nonlinear partial differential equation describing one-dimensional viscous fluid. We consider it to be defined in closed spatial domain $x \in [A,B]$ and for time interval $t \in [0, T]$.

\begin{equation}
\label{eq:BurgEq}
    u_t + u u_x - \nu u_{xx} = 0
\end{equation}

Initial condition $u(x,0)$ is given, as well as two Dirichlet boundary conditions:

\begin{subequations}
\label{eq:BurgEqBCs}
\begin{align}
    u(x,0) = u_0(x), \\
    u(A,t) = f(t), \\
    u(B,t) = 1.
\end{align}
\end{subequations}

Here the left boundary condition, $f(t)$, will act as a control parameter. We would like to optimize it in order to minimize a cost function, for instance, time-averaged viscous dissipation:

\begin{equation}
\mathcal{J} = \left[ \nu \left( \frac{\partial u}{\partial x} \right)^2 \right]
\end{equation}

Following \cite{CossuIntr}, in this example we will treat initial and boundary conditions (\ref{eq:BurgEqBCs}) as given constraints, i.e. in the same as the Burgers equation itself. Another approach, which leads to the same result, is to apply given boundary conditions after the augmented cost function is formed.

The first step is to form a so-called Lagrangian of the system, by adding all state equations multiplied by Lagrange variables to the cost function. This gives:

\begin{subequations}
\begin{align}
    \label{eq:BurgEqAdj0}
    \mathcal{L} = \mathcal{J} - \left[ \lambda, u_t + u u_x - \nu u_{xx} \right] -\\
    - \left< b, u(x,0) - u_0 \right> -  \left\{ C_{\alpha}, u(A,t) - f(t) \right\}  -  \left\{ C_{\beta}, u(B,t) - 1 \right\}
\end{align}
\end{subequations}

Here $\lambda$ is an Lagrange state multiplier, $b$ and $C_{\alpha}, C_{\beta}$ are Lagrange multipliers for initial and boundary conditions, respectively. One can see, that partial derivatives of $\mathcal{L}$ with respect to $\lambda$ produce initial state equation, and initial and boundary equations while differentiation with respect to $b, C_{\alpha}, C_{\beta}$. To construct the adjoint operator, we integrate the differential form in (\ref{eq:BurgEqAdj0}) by parts and apply divergence theorem, which results in:

\begin{subequations}
\label{eq:BurgEqAdj}
\begin{align}
    \label{eq:BurgEqAdj1}
    \mathcal{L} = \mathcal{J} - \left[ -\lambda_t - \frac{1}{2} u \lambda_x - \nu \lambda_{xx}, u \right] -\\
    - \left< \lambda, u \right>^T_0 - \left\{\frac{1}{2} \lambda u - \nu \lambda_x, u \right\}^B_A + \left\{ \nu \lambda, u_x \right\}^B_A - \\
    - \left< b, u(x,0) - u_0 \right> -  \left\{ C_{\alpha}, u(A,t) - f(t) \right\}  -  \left\{ C_{\beta}, u(B,t) - 1 \right\}
\end{align}
\end{subequations}

Now, the total variation of the Lagrangian $\delta \mathcal{L}$ can be written as:

\begin{subequations}
\begin{align}
    \label{eq:BurgEqAdjVariation}
    0 = \delta \mathcal{L} = \delta \mathcal{J} + \left[ \lambda_t + u \lambda_x + \nu \lambda_{xx}, \delta u \right] -\\
    - \left< \lambda(x,T), \delta u(x,T) \right> + \left< \lambda(x,0), \delta u(x,0) \right> - \\
    - \left\{ \lambda u - \nu \lambda_x, \delta u \right\}^B_A + \left\{ \nu \lambda, (\delta u)_x \right\}^B_A - \\
    - \left< b, \delta u(x,0) \right> -  \left\{ C_{\alpha}, \delta u(A,t) \right\}  -  \left\{ C_{\beta}, \delta u(B,t) \right\}
\end{align}
\end{subequations}

Unspecified variation of the cost function, $\delta \mathcal{J}$, is:

\begin{equation}
\delta \mathcal{J} = \left[ - 2 \nu u_xx, \delta u \right] + \left\{ 2 \nu u_x, \delta u  \right\}^B_A
\end{equation}

Finally, gathering terms with the same variation quantity, extracts the adjoint set of equations. The $\left[ \cdot , \delta u \right] $ terms give the adjoint state equation:

\begin{equation}
\lambda_t + u \lambda_x + \nu \lambda_{xx} = 2 \nu u_{xx}
\end{equation}

Worth mentioning that despite this equation is quite similar to the original Burgers equation - it has temporal derivative, convective, and a viscous term, it is linear on $\lambda$, and has a source function. Moreover, viscosity has a different sign in comparison to the direct problem, thus the adjoint problem will be well-posed only if propagates back in time, starting with 'initial data' at the final time $t = T$ \cite{Giles2000}. This means, that integration in time should follow the direct solution backwards.

Gathering the rest terms provides the necessary adjoint boundary and initial conditions:

\begin{subequations}
\begin{align}
    \label{eq:BurgEqAdjBCt0}
    & \delta u(x,0): \ \ \lambda - b = 0 & \Rightarrow \ \ & b = \lambda(x,0),\\
    \label{eq:BurgEqAdjBCtT}
    & \delta u(x,T): \ \ \lambda = 0 & \Rightarrow \ \ & \lambda(x,T) = 0 ,\\
    & \delta u_x(A,t): \ \ \nu \lambda = 0 & \Rightarrow \ \ & \lambda(A,t) = 0, \\
    & \delta u_x(B,t): \ \ \nu \lambda = 0 & \Rightarrow \ \ & \lambda(B,t) = 0, \\
    & \delta u(A,t): \ \ 2 \nu u_x - \lambda u - \nu \lambda_x + C_{\alpha} = 0, \\
    & \delta u(B,t): \ \ 2 \nu u_x - \lambda u - \nu \lambda_x - C_{\beta} = 0
\end{align}
\end{subequations}

The first two conditions (\ref{eq:BurgEqAdjBCt0}) and (\ref{eq:BurgEqAdjBCtT}) are sensitivity to the initial condition $u(x,0) = u_0$ and the adjoint initial condition, which says that $\lambda(x,T) = 0$; the following two are the adjoint boundary conditions, and the last two give us the values of $C_{\alpha}, C_{\beta}$ at $x = A$ and $x = B$, respectively.

Finally, from (\ref{eq:BurgEqAdj}) it is clear, that the sensitivity with respect to the boundary condition $u(A,t) = f(t)$ equals to:

\begin{equation}
\frac{\partial \mathcal{L}}{\partial f} \delta f = \left\{C_{\alpha} , \delta f(t)  \right\}
\end{equation}

And consequently, the gradient of the cost function with respect to $f(t)$ becomes:

\begin{equation}
\nabla \mathcal{J}[f] = \left\{ C_{\alpha} \right\} = \left\{ -2 \nu u_x (A,t) + \nu \lambda_x (A,t) \right\}
\end{equation}

\subsection{Shape optimization of linear acoustic problem}

Now we consider the one-dimensional wave equation in frequency domain, or the Helmholtz equation:

\begin{equation}
    P_{xx} - s^2 P = 0
\end{equation}

This is a spectral problem, where $P_k$ and $s_k$ represent a $k-$th eigenfunction (or natural mode) and an eigenvalue of the given system. The general solution can be written as: $P_k = a_k sin(s_k x) + b_k cos(s_k x)$, where $a_k, b_k$ are some constants subject to boundary conditions.

We aim to perform shape optimization to minimize eigenvalues of the problem; namely, since the problem is 1D, we will find the derivative of the eigenvalue with respect to the position of the left boundary. Without loss of generality, let the initial domain be $x \in [0,1]$, and let us call $V$ the perturbation of the boundary $x = 0$, such that the deformed domain is $x \in [V, 1]$. Additionally, we can recast the cost function to become $\mathcal{J} = \sigma = s^2$.

The augmented cost function for the problem is defined by:

\begin{equation}
\label{eq:HelmhAdj}
    \mathcal{L} = \mathcal{J} + \left<\lambda, P_{xx} - \sigma P \right>
\end{equation}

Note, that we can construct the Lagrangian without knowing the boundary conditions; in contrast to the previous section, we will apply boundary conditions after the Lagrangian variation is obtained.

Integration by parts and taking the variation of the augmented cost function (\ref{eq:HelmhAdj}) leads to:

\begin{subequations}
\begin{align}
    0 = \delta \mathcal{L} = \delta \sigma + \left<\lambda_{xx} - \sigma \lambda , \delta P \right> - \delta \sigma \left< \lambda, P \right> - \\
    - \lambda_x \delta P \rvert^1_0 +  \lambda, \delta P_x \rvert^1_0
\end{align}
\end{subequations}

We can extract two relevant equations from this expression: first, gathering the terms of $\left<\cdot , \delta P \right> $ and the terms proportional to $\delta \sigma$. These yield:

\begin{subequations}
\begin{align}
    & \delta P: \ \  \lambda_{xx} - \sigma \lambda = 0, \\
    & \delta \sigma: \ \ 1 - \left<\lambda, P \right> = 0.
\end{align}
\end{subequations}

The first equation is a differential equation of the adjoint state; the second one is a normalization condition.

Now, we have two boundary terms left, and further derivation of the adjoint boundary condition will depend on the choice of the direct formulation. Here we consider three different cases: dual Dirichlet boundary conditions, dual Neumann boundaries, and a Dirichlet plus Robin boundary conditions.

\clearpage

\section{Adjoints for incompressible Navier-Stokes equation}
\subsection{Governing equations}
\subsection{Adjoint boundary conditions}
\subsection{Shape derivatives and Hadamard structure}
\subsection{Time dependent flow optimization}

\section{Adjoints for acoustic problem}
\subsection{Governing equations}
\subsection{Adjoint boundary conditions}
\subsection{Shape derivatives and Hadamard structure}

\section{Taylor testing for adjoint gradient}
