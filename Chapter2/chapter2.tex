%!TEX root = ../thesis.tex
%*******************************************************************************
%****************************** Second Chapter *********************************
%*******************************************************************************

\chapter{Adjoint based shape optimization}

\ifpdf
    \graphicspath{{Chapter2/Figs/Raster/}{Chapter2/Figs/PDF/}{Chapter2/Figs/}}
\else
    \graphicspath{{Chapter2/Figs/Vector/}{Chapter2/Figs/}}
\fi

Here an later we use the following denominations for scalar products:

\begin{subequations}
\begin{align}
          \left< \cdot, \cdot \right> = \int_{\Omega} dx (\cdot, \cdot ), \\
          \left\{ \cdot, \cdot \right\} = \int_{T} dt (\cdot, \cdot ), \\
          \left[ \cdot, \cdot  \right] = \int_{\Omega} dx\int_{T} dt (\cdot, \cdot )
\end{align}
\end{subequations}


\section{Pedagogical one dimensional optimization}

To start with, we consider two one-dimensional optimization problems: parameter-based unsteady Burgers equation, and Helmholtz equation with adjustable shape. These examples are aimed to give an insight into construction of adjoint systems and how to obtain cost function gradient with respect to different changes in the initial problem.

\subsection{Burgers equation: sensitivity to control parameters}

Burgers equation (\ref{eq:BurgEq}) is a nonlinear partial differential equation describing one-dimensional viscous fluid. We consider it to be defined in closed spatial domain $x \in [A,B]$ and for time interval $t \in [0, T]$.

\begin{equation}
\label{eq:BurgEq}
    u_t + u u_x - \nu u_{xx} = 0
\end{equation}

Initial condition $u(x,0)$ is given, as well as two Dirichlet boundary conditions:

\begin{subequations}
\label{eq:BurgEqBCs}
\begin{align}
    u(x,0) = u_0(x), \\
    u(A,t) = f(t), \\
    u(B,t) = 1.
\end{align}
\end{subequations}

Here the left boundary condition, $f(t)$, will act as a control parameter. We would like to optimize it in order to minimize a cost function, for instance, time-averaged viscous dissipation:

\begin{equation}
\mathcal{J} = \left[ \nu \left( \frac{\partial u}{\partial x} \right)^2 \right]
\end{equation}

Following \cite{CossuIntr}, in this example we will treat initial and boundary conditions (\ref{eq:BurgEqBCs}) as given constraints, i.e. in the same way as the Burgers equation. Another approach, which leads to the same result, is to apply given boundary conditions after the augmented cost function is formed.

The first step is to form the Lagrangian of the system, by adding all state equations multiplied by Lagrange variables to the cost function. This gives:

\begin{subequations}
\begin{align}
    \label{eq:BurgEqAdj0}
    \mathcal{L} = \mathcal{J} - \left[ \lambda, u_t + u u_x - \nu u_{xx} \right] -\\
    - \left< b, u(x,0) - u_0 \right> -  \left\{ C_{\alpha}, u(A,t) - f(t) \right\}  -  \left\{ C_{\beta}, u(B,t) - 1 \right\}
\end{align}
\end{subequations}

Here $\lambda$ is an Lagrange state multiplier, $b$ and $C_{\alpha}, C_{\beta}$ are Lagrange multipliers for initial and boundary conditions, respectively. One can see, that partial derivatives of $\mathcal{L}$ with respect to $\lambda$ produce initial state equation, and initial and boundary equations while differentiation with respect to $b, C_{\alpha}, C_{\beta}$. To construct the adjoint operator, we integrate the differential form in (\ref{eq:BurgEqAdj0}) by parts and apply the divergence theorem, which results in:

\begin{subequations}
\label{eq:BurgEqAdj}
\begin{align}
    \label{eq:BurgEqAdj1}
    \mathcal{L} = \mathcal{J} - \left[ -\lambda_t - \frac{1}{2} u \lambda_x - \nu \lambda_{xx}, u \right] -\\
    - \left< \lambda, u \right>^T_0 - \left\{\frac{1}{2} \lambda u - \nu \lambda_x, u \right\}^B_A + \left\{ \nu \lambda, u_x \right\}^B_A - \\
    - \left< b, u(x,0) - u_0 \right> -  \left\{ C_{\alpha}, u(A,t) - f(t) \right\}  -  \left\{ C_{\beta}, u(B,t) - 1 \right\}
\end{align}
\end{subequations}

Now, the total variation of the Lagrangian $\delta \mathcal{L}$ can be written as:

\begin{subequations}
\begin{align}
    \label{eq:BurgEqAdjVariation}
    0 = \delta \mathcal{L} = \delta \mathcal{J} + \left[ \lambda_t + u \lambda_x + \nu \lambda_{xx}, \delta u \right] -\\
    - \left< \lambda(x,T), \delta u(x,T) \right> + \left< \lambda(x,0), \delta u(x,0) \right> - \\
    - \left\{ \lambda u - \nu \lambda_x, \delta u \right\}^B_A + \left\{ \nu \lambda, (\delta u)_x \right\}^B_A - \\
    - \left< b, \delta u(x,0) \right> -  \left\{ C_{\alpha}, \delta u(A,t) \right\}  -  \left\{ C_{\beta}, \delta u(B,t) \right\}
\end{align}
\end{subequations}

Unspecified variation of the cost function, $\delta \mathcal{J}$, is:

\begin{equation}
\delta \mathcal{J} = \left[ - 2 \nu u_xx, \delta u \right] + \left\{ 2 \nu u_x, \delta u  \right\}^B_A
\end{equation}

Finally, gathering terms with the same variation quantity, extracts the adjoint set of equations. The $\left[ \cdot , \delta u \right] $ terms give the adjoint state equation:

\begin{equation}
\lambda_t + u \lambda_x + \nu \lambda_{xx} = 2 \nu u_{xx}
\end{equation}

Worth mentioning that despite this equation is quite similar to the original Burgers equation - it has temporal derivative, convective, and a viscous term, it is linear on $\lambda$, and has a source function. Moreover, viscosity has a different sign in comparison to the direct problem, thus the adjoint problem will be well-posed only if propagates back in time, starting with 'initial data' at the final time $t = T$ \cite{Giles2000}. This means, that integration in time should follow the direct solution backwards.

Gathering the rest terms provides the necessary adjoint boundary and initial conditions:

\begin{subequations}
\begin{align}
    \label{eq:BurgEqAdjBCt0}
    & \delta u(x,0): \ \ \lambda - b = 0 & \Rightarrow \ \ & b = \lambda(x,0),\\
    \label{eq:BurgEqAdjBCtT}
    & \delta u(x,T): \ \ \lambda = 0 & \Rightarrow \ \ & \lambda(x,T) = 0 ,\\
    & \delta u_x(A,t): \ \ \nu \lambda = 0 & \Rightarrow \ \ & \lambda(A,t) = 0, \\
    & \delta u_x(B,t): \ \ \nu \lambda = 0 & \Rightarrow \ \ & \lambda(B,t) = 0, \\
    & \delta u(A,t): \ \ 2 \nu u_x - \lambda u - \nu \lambda_x + C_{\alpha} = 0, \\
    & \delta u(B,t): \ \ 2 \nu u_x - \lambda u - \nu \lambda_x - C_{\beta} = 0
\end{align}
\end{subequations}

The first two conditions (\ref{eq:BurgEqAdjBCt0}) and (\ref{eq:BurgEqAdjBCtT}) are sensitivity to the initial condition $u(x,0) = u_0$ and the adjoint initial condition, which says that $\lambda(x,T) = 0$; the following two are the adjoint boundary conditions, and the last two give us the values of $C_{\alpha}, C_{\beta}$ at $x = A$ and $x = B$, respectively.

Finally, from (\ref{eq:BurgEqAdj}) it is clear, that the sensitivity with respect to the boundary condition $u(A,t) = f(t)$ equals to:

\begin{equation}
\frac{\partial \mathcal{L}}{\partial f} \delta f = \left\{C_{\alpha} , \delta f(t)  \right\}
\end{equation}

And consequently, the gradient of the cost function with respect to $f(t)$ becomes:

\begin{equation}
\nabla \mathcal{J}[f] = \left\{ C_{\alpha} \right\} = \left\{ -2 \nu u_x (A,t) + \nu \lambda_x (A,t) \right\}
\end{equation}

\subsection{Shape optimization of linear acoustic problem}

Now we consider the one-dimensional wave equation in frequency domain, or the Helmholtz equation:

\begin{equation}
\label{eq:HelmholtzEq}
    P_{xx} - s^2 P = 0
\end{equation}

This is a spectral problem, where $P_k$ and $s_k$ represent a $k-$th eigenfunction (or natural mode) and an eigenvalue of the given system. The general solution can be written as: $P_k = a_k sin(s_k x) + b_k cos(s_k x)$, where $a_k, b_k$ are some constants subject to boundary conditions.

We aim to perform shape optimization to minimize eigenvalues of the problem; namely, since the problem is 1D, we will find the derivative of the eigenvalue with respect to the position of the left boundary. Without loss of generality, let the initial domain be $x \in [0,1]$, and let us call $V$ the boundary displacement field at $x = 0$, such that the deformed domain is $x \in [tV, 1]$. Here $t$ is a parameter which governs the amplitude of the displacement.  Additionally, we can recast the cost function to become $\mathcal{J} = \sigma = s^2$.

The augmented cost function for the problem is defined by:

\begin{equation}
\label{eq:HelmhAdj}
    \mathcal{L} = \mathcal{J} + \left<\lambda, P_{xx} - \sigma P \right>
\end{equation}

Note, that we can construct the Lagrangian without knowing the boundary conditions; in contrast to the previous section, we will apply boundary conditions after the Lagrangian variation is obtained.

Integration by parts and taking the variation of the augmented cost function (\ref{eq:HelmhAdj}) leads to:

\begin{subequations}
\begin{align}
    0 = \delta \mathcal{L} = \delta \sigma + \left<\lambda_{xx} - \sigma \lambda , \delta P \right> - \delta \sigma \left< \lambda, P \right> - \\
    - \left( \lambda_x , \delta P \right) \rvert^1_0 + \left( \lambda , \delta P_x \right) \rvert^1_0
\end{align}
\end{subequations}

We can extract two relevant equations from this expression: first, gathering the terms of $\left<\cdot , \delta P \right> $ and the terms proportional to $\delta \sigma$. These yield:

\begin{subequations}
\begin{align}
    & \delta P: \ \  \lambda_{xx} - \sigma \lambda = 0, \\
    \label{eq:HelmAdjNormCond}
    & \delta \sigma: \ \ 1 - \left<\lambda, P \right> = 0.
\end{align}
\end{subequations}

The first equation is a differential equation of the adjoint state; the second one is a normalization condition.

Now, we have two boundary terms left, and further derivation of the adjoint boundary condition will depend on the choice of the direct formulation. Here we consider three different cases: dual Dirichlet boundary conditions, dual Neumann boundaries, and a Dirichlet plus Robin boundary conditions.

\textbf{Case 1}. Dual Dirichlet boundary conditions.

Let us fix the boundary values $P(0) = P(1) = 0$, therefore the variation $\delta P$ vanishes on the boundaries: $\delta P(0) = \delta P(1) = 0$. This leads to the following representation of the Lagrangian variation:

\begin{equation}
    \delta \mathcal{L} = \left( \lambda , \delta P_x \right) \rvert^1_0 = 0
\end{equation}

Remaining terms are proportional to the unknown $\delta P_x$ thus vanish only if $\lambda(0) = \lambda(1) = 0$, which provides us with the necessary boundary conditions. The problem then becomes self-adjoint, since both the state equation and the boundary conditions are the same for the direct and the adjoint state.

\textbf{Case 2}. Dual Neumann boundary conditions.

Almost the same results can be obtained while considering two Neumann boundary conditions: $P_x(0) = P_x(1) = 0$, except that now another boundary term disappears leaving us with:

\begin{equation}
    \delta \mathcal{L} = -\left( \lambda_x , \delta P \right) \rvert^1_0 = 0
\end{equation}

Therefore we should impose two homogeneous Neumann boundary conditions on $\lambda$ in order to eliminate unknown variations of $\delta P$. As a consequence, the problem is still self-adjoint with $\lambda_x(0) = \lambda_x(1) = 0$.

\textbf{Case 3}. Dirichlet and Robin boundary conditions.

Finally, let us introduce a mixed boundary condition at $x = 0$ and the Dirichlet at $x = 1$. Namely, $k P(0) - P_x (0) = 0$ and $P(1) = 0$, where $k$ is some given constant. First, the boundary term proportional to $\delta P(1)$ is zero, and the second boundary term at $x=1$ can be zero only if $\lambda(1) = 0$. Then, the remaining expression equals to:

\begin{equation}
    \delta \mathcal{L} = \left( \lambda_x(0) , \delta P(0) \right) - \left( \lambda(0) , \delta P_x (0) \right)  = 0
\end{equation}

The variation of the Robin boundary condition allows us to express $\delta P(0)$ or $\delta P_x(0)$ through each other, i.e. $\delta k P(0) = \delta P_x(0)$ and apply this to the boundary terms:

\begin{equation}
    \delta \mathcal{L} = \left( \lambda_x(0) , \delta P(0) \right) - \left( \lambda(0) , k \delta P (0) \right)  = \left( \lambda_x(0) - k \lambda(0) , \delta P (0) \right) = 0
\end{equation}

This gives us the Robin boundary condition on $\lambda$, and as we can see, the direct and the adjoint problems are equivalent as well as in the previous cases. These results can be reformulated as follows: the problem (\ref{eq:HelmholtzEq}) with the squared eigenvalue as the objective function is self-adjoint, and in order to obtain the adjoint field $\lambda$ one should apply the normalization condition (\ref{eq:HelmAdjNormCond}).

Following \cite{Schmidt2010}, but with the simplification to 1D case, we can present the full variation (or the material derivative) as a sum of local and spatial derivatives:

\begin{equation}
    dP[V](x) = \left.\frac{d}{dt} \right\rvert_{t=0} P_t (x_t) = \left.\frac{\partial}{\partial t}\right\rvert_{t=0} P_t + \left.\frac{\partial P}{\partial x}\right\rvert_{t=0} \frac{d x_t}{d t}
\end{equation}

Here $[V]$ stands for the derivative with respect to shape, and $_t$ index corresponds to the shifted boundary point or the solution in the changed domain. According to the definition $x_t = tV$, so the total derivative becomes:

\begin{equation}
dP[V](x) = P'[V] + V P_x 
\end{equation}

Following the same logic, the material derivative of the spatial derivative $P_x$ can be written as:

\begin{equation}
dP_x[V](x) = \left(P'[V]\right)' + V P_{xx} 
\end{equation}

Now, to cover all three cases at once, let us derive the shape derivative of the objective function for Case 3. First, from the Robin boundary condition and using the expressions for the material derivatives:

\begin{equation}
d(P_x - k P) = 0 \ \ \Rightarrow \ \ \left(P'[V]\right)' = k P'[V] + k V P_x -  V P_{xx}
\end{equation}

And the Lagrangian shape derivative

\begin{subequations}
\begin{align}
\mathcal{L}'[V] = \left( \lambda_x , P'[V] \right)_{x = 0} - \left( \lambda , \left(P'[V]\right)'  \right)_{x = 0} = \\
\label{eq:HelmhShapeDerRobin}
\left( \lambda_x - k \lambda, P'[V] \right)_{x = 0}- \left( \lambda , k V P_x - VP_{xx}  \right)_{x = 0}
\end{align}
\end{subequations}

Since the system is self-adjoint, we can use $P(x)$ instead of $\lambda(x)$ (keeping in mind the normalization condition), the first bracket in (\ref{eq:HelmhShapeDerRobin}) is zero due to the boundary condition; and the shape derivative finally is:

\begin{equation}
\label{eq:HelmholtzEqGrad}
    d \sigma [V] = V \left( P P_{xx} - k P P_x \right)_{x = 0}
\end{equation}

We can apply the given boundary condition here, thereby the shape derivative doesn't depend on $k$:

\begin{equation}
\label{eq:HelmholtzEqGradNok}
    d \sigma [V] = V \left( P P_{xx} - P_x^2 \right)_{x = 0}
\end{equation}

Summing up, once the solution of the spectral problem (\ref{eq:HelmholtzEq}) is obtained, to calculate the shape derivative of the cost function $\mathcal{J} = s^2$ with respect to shape one needs to normalize the eigenfunction such way that $1 = \left<P,P\right>$, and then the desired gradient equals to (\ref{eq:HelmholtzEqGradNok}).

\clearpage

\section{Adjoints for incompressible Navier-Stokes equation}
\subsection{Governing equations}
\subsection{Adjoint boundary conditions}
\subsection{Shape derivatives and Hadamard structure}
\subsection{Time dependent flow optimization}

\section{Adjoint viscous acoustic problem}

In this section we derive and discuss the adjoint formulation of the viscous acoustic problem. First, we formulate the governing equations of the adjoint state; second, the adjoint boundary conditions are presented, and third, the shape derivative in the Hadamard form is constructed.

\subsection{Governing equations}

Let us recall the formulation of the direct problem, (\ref{eq:strViscAc}). We will use the following form of the mass and momentum conservation equations in the frequency domain:

\begin{subequations}
\begin{align}
\label{eq:strViscAc2}
        s \hat{\rho} + div(\hat{u}) = 0, \\
        s \hat{u}_i - \nabla_j \hat{\sigma}_{ij} = 0 .
\end{align}
\end{subequations}

We aim to control the natural frequencies of the system, therefore the $s$ is the cost function $\mathcal{J} = s$. We obtain the augmented cost function by multiplying the first equation in (\ref{eq:strViscAc2}) by a scalar function $-w$ and the second equation by a vector function $v_i$. Now, the Lagrangian can be written as:

\begin{equation}
\mathcal{L} = \mathcal{J} - \left< -w, s \hat{\rho} + div(\hat{u}) \right> - \left< v_i, s \hat{u}_i - \nabla_j \hat{\sigma}_{ij} \right>
\end{equation}

We integrate the volume integrals by parts, and regroup the terms:

\begin{equation}
\label{eq:AdjLagrang}
\mathcal{L} = \left< s w + div(v), \hat{\rho} \right> -  \left< s v_i - \nabla_j \sigma_{ij}^\dagger, \hat{u}_i \right> + \left\{ v_i, \hat{\sigma}_{ij}  n_j \right\} - \left\{ \sigma_{ij}^\dagger n_j, \hat{u}_i  \right\}
\end{equation}

As stated previously, $\left<\cdot, \cdot \right>$ here denotes volume integrals, while $\left\{ \cdot, \cdot \right\}$ is used to describe surface integrals. We denote the stress tensor operator acting on the co-state space $(w, v_i)$ as $\sigma_{ij}^\dagger$. Now, the variation of the Lagrangian with respect to $s$ and $\hat{\rho}, \hat{u}_i$ results in the adjoint set of equations:

\begin{subequations}
\label{eq:AdjAcoustProblem}
\begin{flalign}
    \label{eq:AdjAcoustNormCond}
    &\delta s: \left< \hat{u}_i v_i - \rho w \right> = 1,\\&
    \delta \hat{\rho}: s w + div(v) = 0,\\ &
    \delta \hat{u}_i: s v_i -\nabla_j \sigma_{ij}^\dagger = 0
\end{flalign}
\end{subequations}

Here, the first equation acts as a normalization condition, and the second and third equations describe the adjoint mass and momentum conservation laws. Note, that the state and co-state equations are equal; we expect the system to be self-adjoint. To show this, let us consider the possible boundary conditions.

\subsection{Adjoint boundary conditions}

We consider three types of boundary conditions of the direct problem: no-slip boundary $\hat{u}_i = 0$, stress free boundary $\hat{\sigma}_{ij} n_j = 0$, and comliant boundary $Z \hat{u}_i = \hat{\sigma}_{ij} n_j$. For each of the boundary types we will focus on the surface integrals in (\ref{eq:AdjLagrang}) since the volumetric terms vanish due to the choice of the adjoint state equations.

The general expression of the surface terms varitation reads as:

\begin{equation}
\label{eq:AdjLagrangVarSurface}
\delta \mathcal{L} = \left\{ v_i , \delta \hat{\sigma}_{ij} n_j \right\} - \left\{\sigma_{ij}^\dagger  n_j,  \delta \hat{u}_i \right\} = 0
\end{equation}

\subsubsection{No-slip boundary}

The variation of the no-slip Dirichlet boundary condition is zero, $\delta \hat{u}_i = 0$, which leaves us with the following condition:

\begin{equation}
\left\{ v_i, \delta \hat{\sigma}_{ij}  n_j \right\}_{\Gamma_{nsl}} = 0
\end{equation}

Since the stress value is not specified on the no-slip boundary, we set the adjoint velocity $v_i$ to zero:

\begin{equation}
v_i = 0 \ \ on \ \ \Gamma_{nsl}
\end{equation}

\subsubsection{Free boundary}

On the free boundary, the stress vector is given thus its variation is zero. The Lagrangian variation then becomes

\begin{equation}
- \left\{\sigma_{ij}^\dagger  n_j,  \delta \hat{u}_i \right\}_{\Gamma_{free}} = 0
\end{equation}

And in order to eliminate the unknown velocity variation on the free boundary, we choose adjoint stress to be zero as well:

\begin{equation}
\sigma_{ij}^\dagger  n_j = 0 \ \ on \ \ \Gamma_{free}
\end{equation}

\subsubsection{Compliant boundary}

The compliant boundary condition couples the velocity and the stress on the surface, therefore the variation of the boundary condition is $Z \delta \hat{u}_i = \delta \hat{\sigma}_{ij} n_j$. Although the impedance value depends on the oscillation frequency $Z = Z(s)$, we assume that the variation of $Z$ is zero, i.e. neglect that the boundary impedance is not constant. We substitute the variation expression into (\ref{eq:AdjLagrangVarSurface}) to obtain

\begin{equation}
\left\{ v_i , Z \delta \hat{u}_i \right\}_{\Gamma_{comp}} - \left\{\sigma_{ij}^\dagger  n_j,  \delta \hat{u}_i \right\}_{\Gamma_{comp}} = \left\{ Z v_i -\sigma_{ij}^\dagger  n_j , \delta \hat{u}_i \right\}_{\Gamma_{comp}} =  0
\end{equation}

The surface integral is proportional to unknown $\delta \hat{u}_i$, so the compliant adjoint boundary condition becomes

\begin{equation}
Z v_i = \sigma_{ij}^\dagger  n_j \ \ on \ \ \Gamma_{comp}
\end{equation}

First, note, that all the adjoint boundary conditions are equivalent to the direct formulation. This proves that the proposed problem is self-adjoint. Second, the compliant boundary is a generalized case of the no-slip and stress free boundaries; if $Z$ approaches infinity, the boundary acts like a no-slip, and represents a free surface if $Z \to 0$. Consequently, once we obtain any result for the compliant boundary, it can be easily applied to all other mentioned cases without any additional effort.


Summing up, we have derived the adjoint boundary conditions for no-slip, stress free, and compliant boundaries. It appears, that they are similar to those of the direct problem, and as soon as the adjoint governing equations coincide with the primal formualtion, the problem is self-adjoint. The only step to calculate the adjoint quantities is to apply the normalization condition (\ref{eq:AdjAcoustNormCond}). 

\subsection{Shape derivative and Hadamard structure}

Let us recall the main concept of the Hadamard formula first: for a sufficiently smooth cost function, $\mathcal{J}$, the shape derivative $d\mathcal{J}[V]$ can be written as a surface integral of the given domain perturbation field $V$ and a functional $G$. In our case, we aim to construct the gradient of the cost function (eigenvalue) by deriving the integrand $G$ as a function of the direct and adjoint states: $G = G(\textbf{q}, \textbf{q}\dagger)$. Since the problem we consider is self-adjoint, the Hadamard formula yields:

\begin{equation}
d\mathcal{J}[V] = \int_{\partial \Omega} (V,n) G(\textbf{q}) d\Gamma
\end{equation}

As shown below, all considered boundary conditions thus shape derivatives can be translated to the single case of the compliant boundary. Using the chain rule, the material derivative of the boundary condition satisfies

\begin{subequations}
\begin{align}
0 = d(Z \hat{u}_i - \hat{\sigma}_{ij} n_j)[V] = \\
Z d\hat{u}_i[V] - d\hat{\sigma}_{ij}[V] n_j - \hat{\sigma}_{ij} d n_j[V]
\end{align}
\end{subequations}

Following \cite{Schmidt2010}, the differential of a function $f_t$ satisfying the PDE constraint on a perturbed domain $\Omega_t = T_t(\Omega),$ where $T_t(x) = x + tV(x)$, can be transferred back to the original domain $\Omega$. Then, the material derivative $df[V]$ is related to local derivative $f'[V]$ as

\begin{equation}
df[V](x) = \left. \frac{d}{dt}\right|_{t=0} f_t(x_t) = \left. \frac{d}{dt}\right|_{t=0} f_t(x) + \frac{\partial f}{\partial x}  \left. \frac{d}{dt}\right|_{t=0} x_t = f'[V] + (V,\nabla) f
\end{equation}

Then, the boundary derivative terms read as

\begin{subequations}
\begin{align}
d\hat{u}_i [V] = \hat{u}_i'[V] + (V,\nabla) \hat{u}_i,  \\
d\hat{\sigma}_{ij}[V] = \hat{\sigma}_{ij}'[V] + (V,\nabla) \hat{\sigma}_{ij}
\end{align}
\end{subequations}

Specifically, for the perturbation normal to the boundary $V = (V,n)n$, the shape derivative of the normal is given by tangent gradient of the displacement, $\nabla_i^{\Gamma} (V,n)$. The tangent gradient is defined as gradient minus its normal component $\nabla_i^{\Gamma} = \nabla_i  - n_i \partial_n$. 

\begin{equation}
d n_i[V] = - \nabla_i^{\Gamma} (V,n)
\end{equation}

The eigenvalue shape derivative of the problem (\ref{eq:AdjAcoustProblem}) now becomes

\begin{subequations}
\begin{align}
&d \mathcal{J} [V] = \left\{ v_i , \hat{\sigma}_{ij}'[V] n_j \right\} &-& \left\{\sigma_{ij}^\dagger  n_j,  \hat{u}_i'[V] \right\} = \\
&\left\{ v_i ,d\hat{\sigma}_{ij}[V] n_j - (V,\nabla) \hat{\sigma}_{ij} n_j \right\} &-& \left\{\sigma_{ij}^\dagger  n_j,  d\hat{u}_i [V] - (V,\nabla) \hat{u}_i \right\} = \\
&\left\{ v_i , Z d\hat{u}_i [V] - \hat{\sigma}_{ij} dn_j[V] - (V,\nabla) \hat{\sigma}_{ij} n_j \right\} &-& \left\{\sigma_{ij}^\dagger  n_j,  d\hat{u}_i [V] - (V,\nabla) \hat{u}_i \right\} = \\
&\left\{ \hat{u}_i , Z d\hat{u}_i [V] - \hat{\sigma}_{ij} dn_j[V] - (V,\nabla) \hat{\sigma}_{ij} n_j \right\} &-& \left\{\hat{\sigma}_{ij}  n_j,  d\hat{u}_i [V] - (V,\nabla) \hat{u}_i \right\} = \\
&\left\{ \hat{u}_i , - \hat{\sigma}_{ij} dn_j[V] - (V,\nabla) \hat{\sigma}_{ij} n_j \right\} &-& \left\{\hat{\sigma}_{ij}  n_j,  - (V,\nabla) \hat{u}_i \right\}
\end{align}
\end{subequations}

Considering only normal boundary displacement, the shape derivative becomes

\begin{equation}
\label{eq:ShapeDerAcoustNotHadam}
d \mathcal{J} [V] = \left\{ (V,n) \left(\frac{\partial \hat{u}_i}{\partial n} n_j \hat{\sigma}_{ij} -  \hat{u}_i n_j \frac{\partial \hat{\sigma}_{ij}}{\partial n}\right) + \hat{u}_i \hat{\sigma}_{ij} \nabla_j^{\Gamma} (V,n) \right\}
\end{equation}

This is still not in the Hadamard form, so we apply the surface tangential Green's formula \cite{Delfour} to the last term. The relation holds for a smooth vector field $A$ and a scalar field $b$:

\begin{equation}
(A , \nabla^{\Gamma}) b = \kappa b (A,n)   - b \ div^{\Gamma} A
\end{equation}

Here $\kappa = div^{\Gamma}n$ describes the surface curvature. The transformation to the Hadamard form is given by

\begin{equation}
\hat{u}_i \hat{\sigma}_{ij} \nabla_j^{\Gamma} (V,n) = \kappa (V,n) \hat{u}_i \hat{\sigma}_{ij} n_j - (V,n) \nabla_j^{\Gamma} (\hat{u}_i \hat{\sigma}_{ij})
\end{equation}

Furthermore, using the definition of the tangential gradient, the relation holds:

\begin{equation}
\nabla_j^{\Gamma} (\hat{u}_i \hat{\sigma}_{ij}) + \hat{u}_i n_j \frac{\partial \hat{\sigma}_{ij}}{\partial n} = \nabla_j (\hat{u}_i \hat{\sigma}_{ij}) - \frac{\partial \hat{u}_i}{\partial n} n_j \hat{\sigma}_{ij} 
\end{equation}

After rearranging the terms in (\ref{eq:ShapeDerAcoustNotHadam}), the shape derivative of the system's eigenvalue becomes:

\begin{equation}
\label{eq:ShapeDerAcoustHadam}
d s [V] = \left\{ (V,n) \left( 2 \frac{\partial \hat{u}_i}{\partial n} n_j \hat{\sigma}_{ij} - \nabla_j \left( \hat{u}_i \hat{\sigma}_{ij} \right)  + \kappa \hat{u}_i \hat{\sigma}_{ij} n_j \right) \right\}
\end{equation}

A few comments to be made regarding the shape derivative expressions. First, two forms (\ref{eq:ShapeDerAcoustNotHadam}) and (\ref{eq:ShapeDerAcoustHadam}) are equivalent. Second, they do not depend on $Z$, thus are applicable to any considered boundary type. Third, in case $\hat{u}_i$ or $\hat{\sigma}_{ij} n_j$ is zero, some of the terms vanish which can be useful in case of a single boundary type evaluation. 

\section{Taylor testing for adjoint gradient}
